b'<!DOCTYPE html>\n<html lang="en">\n<head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/>\n<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>\n<!-- <meta http-equiv="X-UA-Compatible" content="IE=edge"> -->\n<!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->\n<title>CS229: Machine Learning</title>\n<!-- bootstrap -->\n<!-- <link rel="stylesheet" href="./style/bootstrap.min.css"> -->\n<link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" rel="stylesheet"/>\n<link href="./style/bootstrap-theme.min.css" rel="stylesheet"/>\n<link href="./style/newstyle.css" rel="stylesheet" type="text/css"/>\n</head><body>\n<nav class="navbar navbar-expand-md navbar-dark">\n<a href="http://cs229.stanford.edu/">\n<img src="./static/seal-dark-red.png" style="height:40px; float: left; margin-left: 20px; margin-right: 20px;"/></a>\n<a class="navbar-brand" href="http://cs229.stanford.edu/">CS229</a>\n<button aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#navbarsExampleDefault" data-toggle="collapse" type="button">\n<span class="navbar-toggler-icon"></span>\n</button>\n<div class="collapse navbar-collapse" id="navbarsExampleDefault">\n<ul class="navbar-nav mr-auto">\n<li class="nav-item"><a class="nav-link" href="./index.html#announcement">Announcements</a></li>\n<li class="nav-item"><a class="nav-link" href="./syllabus.html">Syllabus</a></li>\n<li class="nav-item"><a class="nav-link" href="./index.html#info">Course Info</a></li>\n<li class="nav-item"><a class="nav-link" href="./index.html#logistics">Logistics</a></li>\n<li class="nav-item"><a class="nav-link" href="projects.html">Projects</a></li>\n<li class="nav-item"><a class="nav-link" href="https://piazza.com/class/spring2019/cs229">Piazza</a></li>\n</ul>\n</div>\n</nav>\n<div class="sechighlight">\n<div class="container sec" style="margin-top: 1em">\n<h2>Syllabus and Course Schedule</h2>\n<p>\n<b>Time and Location</b>:\n  Monday, Wednesday 9:30am-10:50am, <a href="https://campus-map.stanford.edu/?srch=nvidia%20auditorium">NVIDIA Auditorium</a><br/>\n<strong>Class Videos</strong>:\n    Current quarter\'s class videos are available <a href="http://scpd.stanford.edu">here</a> for SCPD students and <a href="https://mvideox.stanford.edu/">here</a> for non-SCPD students.</p>\n<br/>\n</div>\n</div>\n<div class="container">\n<table class="table table-bordered no-more-tables" id="schedule">\n<thead class="active" style="background-color:#f9f9f9">\n<th>Event</th><th>Date</th><th>Description</th><th>Materials and Assignments</th>\n</thead>\n<tbody>\n<!--<tr>\n    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:#fffde7">\n      <strong>Introduction</strong> (1 class)\n    </td>\n  </tr>-->\n<tr>\n<td>Lecture\xc2\xa01</td>\n<td> 9/23 </td>\n<td>\n      Introduction and Basic Concepts\n    </td>\n<td>\n</td>\n</tr>\n<!--<tr>\n    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:#fffde7">\n      <strong>Supervised learning</strong> (6 classes)\n    </td>\n  </tr>-->\n<tr>\n<td>Lecture\xc2\xa02</td>\n<td>9/25</td>\n<td>Supervised Learning Setup. Linear Regression.\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Supervised Learning, Discriminative Algorithms <!-- [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes1.ps">ps</a>] --> [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes1.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Assignment</td>\n<td>9/26</td>\n<td colspan="3" style="text-align:center; vertical-align:middle;">\n<strong>Problem Set 0</strong> <a href="https://piazza.com/class/k0s9q710pjn29t?cid=43">[link]</a>. Due Wednesday, Oct 2 at 11:59pm\n    </td>\n</tr>\n<tr>\n<td>Section 1</td>\n<td>9/28</td>\n<td>\n<strong>Friday Lecture</strong>: Linear Algebra. \n    </td>\n<td>\n<strong>Notes</strong>\n<ul>\n<li>Linear Algebra Review and Reference [<a href="http://cs229.stanford.edu/section/cs229-linalg.pdf">pdf</a>]</li>\n<li>Linear Algebra, Multivariable Calculus, <br/> and Modern Applications <br/> (Stanford Math 51 course text) [<a href="https://web.stanford.edu/class/math51/stanford/math51book.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa03</td>\n<td>9/30</td>\n<td rowspan="2">\n      Weighted Least Squares. Logistic Regression. Netwon\'s Method <br/>\n      Perceptron. Exponential Family. Generalized Linear Models.\n    </td>\n<td rowspan="2">\n<strong>Class Notes</strong>\n<ul>\n<li>Generative Algorithms [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes2.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa04</td>\n<td>10/2</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Assignment</td>\n<td>10/2</td>\n<td colspan="3" style="text-align:center; vertical-align:middle;">\n<strong>Problem Set 1</strong> <a href="https://piazza.com/class/k0s9q710pjn29t?cid=149">[link]</a>. Due Wednesday, Oct 16 at 11:59pm\n    </td>\n</tr>\n<tr>\n<td>Section 2</td>\n<td>10/4</td>\n<td>\n<strong>Friday Lecture</strong>: Probability <!-- [<a href="http://cs229.stanford.edu/section/cs229-prob.pdf">Notes</a>][<a href="http://cs229.stanford.edu/section/cs229-prob-slide.pdf">Slides</a>] -->\n</td>\n<td>\n<strong>Notes</strong>\n<ul>\n<li>Probability Theory Review [<a href="http://cs229.stanford.edu/section/cs229-prob.pdf">pdf</a>] </li>\n<li>The Multivariate Gaussian Distribution [<a href="http://cs229.stanford.edu/section/gaussians.pdf">pdf</a>] </li>\n<li>More on Gaussian Distribution [<a href="http://cs229.stanford.edu/section/more_on_gaussians.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa05</td>\n<td>10/7</td>\n<td>\n      Gaussian Discriminant Analysis. Naive Bayes.\n    </td>\n<td>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa06</td>\n<td>10/9</td>\n<td>\n      Laplace Smoothing. Support Vector Machines. <br/>\n</td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Support Vector Machines [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes3.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Section 3</td>\n<td>10/11</td>\n<td>\n<strong>Friday Lecture</strong>: Python and Numpy<!-- <a href="https://d1b10bmlvqabco.cloudfront.net/attach/jkbylqx4kcp1h3/jm8g1m67da14eq/jn7zkozyyol7/CS229_Python_Tutorial.pdf">[slides]</a> <Vectorization[<a href="http://cs229.stanford.edu/section/vec_demo/Vectorization_Section.pdf">Slides</a>][<a href="http://cs229.stanford.edu/section/vec_demo/knn.py">kNN</a>][<a href="http://cs229.stanford.edu/section/vec_demo/lr.ipynb">Logistic Regression</a>][<a href="http://cs229.stanford.edu/section/vec_demo/sr.ipynb">Softmax Regression</a>][<a href="http://cs229.stanford.edu/section/vec_demo/images.csv">images</a>][<a href="http://cs229.stanford.edu/section/vec_demo/labels.csv">labels</a> -->\n</td>\n<td>\n<strong> Notes</strong>\n<ul>\n<li> Python Tutorial [<a href="http://cs229.stanford.edu/section/cs229_python_friday.pptx">pptx</a>] [<a href="http://cs229.stanford.edu/section/python_tutorial.zip">code</a>]</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa07</td>\n<td>10/14</td>\n<td colspan="2">\n      Support Vector Machines. Kernels.\n    </td>\n</tr>\n<!--   <tr>\n    <td>Lecture&nbsp;2</td>\n    <td> 9/27 </td>\n    <td rowspan="6">\n      <strong>Supervised learning</strong> (5 classes)\n                 <ol>\n                  <li>Supervised learning setup.  LMS.</li>\n                  <li>Logistic regression.  Perceptron.  Exponential family.  </li>\n                  <li>Generative learning algorithms. Gaussian discriminant analysis.  Naive Bayes. </li>\n                  <li>Support vector machines.  </li>\n                  <li>Model selection and feature selection. </li>\n                  <li>Evaluating and debugging learning algorithms. </li>\n                </ol>\n            </td>\n    <td rowspan="6">\n      <strong>Class Notes</strong>\n      <ul>\n      <li>Generative Algorithms [<a href="http://cs229.stanford.edu/notes/cs229-notes2.ps">ps</a>] [<a href="http://cs229.stanford.edu/notes/cs229-notes2.pdf">pdf</a>] </li>\n      <li>Support Vector Machines [<a href="http://cs229.stanford.edu/notes/cs229-notes3.ps">ps</a>] [<a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf">pdf</a>] </li>\n      </ul>\n\n      <strong>Problem Set 1</strong> <a href="ps/ps1/ps1.pdf">[pdf]</a>. Out 10/4. Due 10/18. <a href="gradescope.html">Submission instructions</a>.<br>\n      <strong>Discussion Section: Probability</strong> [<a href="http://cs229.stanford.edu/section/cs229-prob.pdf">Notes</a>][<a href="http://cs229.stanford.edu/section/cs229-prob-slide.pdf">Slides</a>]<br>\n      <strong>Discussion Section: Vectorization</strong> [<a href="http://cs229.stanford.edu/section/vec_demo/Vectorization_Section.pdf">Slides</a>][<a href="http://cs229.stanford.edu/section/vec_demo/knn.py">kNN</a>][<a href="http://cs229.stanford.edu/section/vec_demo/lr.ipynb">Logistic Regression</a>][<a href="http://cs229.stanford.edu/section/vec_demo/sr.ipynb">Softmax Regression</a>]<br>\n    </td>\n  </tr>\n  <tr>\n    <td>\n      Section\n    </td>\n    <td> 9/29 </td>\n  </tr>\n  <tr>\n    <td>Lecture&nbsp;3</td>\n    <td> 10/2 </td>\n  </tr>\n\n  <tr>\n    <td>Lecture&nbsp;4</td>\n    <td> 10/4 </td>\n  </tr>\n\n  <tr>\n    <td>Lecture&nbsp;5</td>\n    <td> 10/9 </td>\n  </tr>\n\n  <tr>\n    <td>Lecture&nbsp;6</td>\n    <td> 10/11 </td>\n\n  </tr> -->\n<!--<tr>\n    <td colspan="4" style="text-align:center; vertical-align:middle;background-color:#fffde7">\n      <strong>Learning theory </strong> (2 classes)\n    </td>\n  </tr>-->\n<tr>\n<td>Lecture\xc2\xa08</td>\n<td> 10/16 </td>\n<td>Neural Networks - 1\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<!-- <li>Bias/variance tradeoff and error analysis[<a href="http://cs229.stanford.edu/section/error-analysis.pdf">pdf</a>]</li> -->\n<li>Deep Learning [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes-deep_learning.pdf">pdf</a>] </li>\n<li>Backpropagation [<a href="http://cs229.stanford.edu/notes/cs229-notes-backprop.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Assignment</td>\n<td>10/16</td>\n<td colspan="3" style="text-align:center; vertical-align:middle;">\n<strong>Problem Set 2</strong> <a href="https://piazza.com/class/k0s9q710pjn29t?cid=428">[link]</a>. Due Wednesday, Oct 30 at 11:59pm\n      <br/>\n</td>\n</tr>\n<tr>\n<td>Section 4</td>\n<td>10/18</td>\n<td>\n<strong>Friday Lecture</strong>: Evaluation Metrics\n    </td>\n<td>\n<strong>Notes</strong>\n<ul>\n<li>Evaluation Metrics [<a href="http://cs229.stanford.edu/section/evaluation_metrics.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Project</td>\n<td> 10/18 </td>\n<td colspan="2" style="text-align:center; vertical-align:middle;"><strong>Project proposal</strong> due 10/18 at 11:59pm.</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa09</td>\n<td> 10/21 </td>\n<td>\n\t    Neural Networks - 2\n    </td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa010</td>\n<td>10/23</td>\n<td>\n      Bias - Variance. Regularization. Feature / Model selection.\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Regularization and Model Selection [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes5.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Section 5</td>\n<td>10/25</td>\n<td>\n<strong>Friday Lecture</strong>: Deep Learning\n    </td>\n<td>\n<strong>Notes</strong>\n<ul>\n<li>Deep Learning [<a href="http://cs229.stanford.edu/section/deep_learning.pdf">pdf</a>]\n      </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa011</td>\n<td>10/28</td>\n<td>Practical Advice for ML projects.\n      </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>ML Advice [<a href="http://cs229.stanford.edu/materials/ML_Advice_Lecture-2019-Oct28.pdf">pdf</a>]</li>\n<!-- <li>Advice on applying machine learning [<a href="http://cs229.stanford.edu/materials/ML-advice.pdf">pdf</a>]</li> -->\n</ul>\n</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Assignment</td>\n<td>10/30</td>\n<td colspan="3" style="text-align:center; vertical-align:middle;">\n<strong>Problem Set 3</strong> <a href="https://piazza.com/class/k0s9q710pjn29t?cid=731">[link]</a>. Due Wednesday, Nov 13 at 11:59pm<br/>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa012 </td>\n<td>10/30</td>\n<td>K-Means. GMM (non EM). Expectation Maximization.\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Unsupervised Learning, k-means clustering. [<a href="http://cs229.stanford.edu/notes/cs229-notes7a.pdf">pdf</a>]</li>\n<li>Mixture of Gaussians [<a href="http://cs229.stanford.edu/notes/cs229-notes7b.pdf">pdf</a>] </li>\n<li>The EM Algorithm [<a href="http://cs229.stanford.edu/notes/cs229-notes8.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Section 6</td>\n<td>11/1</td>\n<td>\n<strong>Friday Lecture</strong>: Midterm Review\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Midterm review  [<a href="materials/midterm-review.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa013</td>\n<td>11/4</td>\n<td>Expectation Maximization. Factor Analysis.</td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Factor Analysis [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes9.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Midterm</td>\n<td>11/5</td>\n<td colspan="2">\n<span style="text-align: left;">The midterm details are posted <a href="https://piazza.com/class/k0s9q710pjn29t?cid=62">on Piazza</a>.</span>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa014</td>\n<td> 11/6 </td>\n<td>Principal and Independent Component Analysis.</td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Principal Components Analysis [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes10.pdf">pdf</a>] </li>\n<li>Independent Component Analysis [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes11.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Section 7</td>\n<td>11/8</td>\n<td>\n<strong>Friday Lecture</strong>: Decision Trees. Boosting. Bagging.\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Decision trees [<a href="http://cs229.stanford.edu/notes/cs229-notes-dt.pdf">pdf</a>] </li>\n<li>Decision tree ipython demo [<a href="http://cs229.stanford.edu/notes2019fall/ta_lecture/decision_tree_demo.ipynb">ipynb</a>] </li>\n<li>Boosting algorithms and weak learning [<a href="http://cs229.stanford.edu/extra-notes/boosting.pdf">pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa015</td>\n<td> 11/11 </td>\n<td rowspan="2"> Weak Supervision</td>\n<td rowspan="2">\n<strong>Class Notes</strong>\n<ul>\n<li>Weak Supervision [<a href="http://cs229.stanford.edu/notes2019fall/weak_supervision_slides.pdf">slides pdf</a>] </li>\n<li>Weak Supervision [<a href="http://cs229.stanford.edu/notes2019fall/weak_supervision_notes.pdf">notes pdf</a>] </li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa016</td>\n<td> 11/13</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Assignment</td>\n<td>11/13</td>\n<td colspan="3" style="text-align:center; vertical-align:middle;">\n<strong>Problem Set 4</strong>\n<a href="https://piazza.com/class/k0s9q710pjn29t?cid=1032">[link]</a>\n      . Due Wednesday, Dec 4 at 11:59pm<br/>\n</td>\n</tr>\n<tr>\n<td>Section 8</td>\n<td>11/15</td>\n<td>\n<strong>Friday Lecture</strong>: On critiques of Machine Learning\n    </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>On critiques of ML [<a href="materials/critiques-ml-aut19.pdf">slides</a>] </li>\n</ul>\n</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Project</td>\n<td> 11/15 </td>\n<td colspan="2"><strong>Project milestones</strong> due 11/15 at 11:59pm.</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa017 </td>\n<td> 11/18 </td>\n<td> Value Iteration and Policy Iteration </td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Reinforcement Learning and Control [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes12.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa018</td>\n<td> 11/20 </td>\n<td>Bias and Variance</td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Bias / Variance [<a href="http://cs229.stanford.edu/summer2019/BiasVarianceAnalysis.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa019</td>\n<td> 12/2 </td>\n<td>Learning Theory</td>\n<td>\n<strong>Class Notes</strong>\n<ul>\n<li>Learning Theory [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes4.pdf">pdf</a>]</li>\n</ul>\n</td>\n</tr>\n<tr>\n<td>Lecture\xc2\xa020</td>\n<td> 12/4 </td>\n<td>Course wrap-up. Beyond CS229 Guest Lectures! Details <a href="https://piazza.com/class/k0s9q710pjn29t?cid=1150">[link]</a></td>\n<td></td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Project</td>\n<td> 12/11 </td>\n<td colspan="2"> <strong>Poster submission</strong> deadline, due 12/11 at 11:59pm (no late days).</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Project</td>\n<td> 12/12 </td>\n<td colspan="2"> <strong>Poster presentations</strong> from 8:30-11:30am.  Venue and details to be announced.</td>\n</tr>\n<tr style="text-align:center; vertical-align:middle;background-color:#FFF2F2">\n<td>Project</td>\n<td> 12/13 </td>\n<td colspan="2"><strong>Project final report</strong> due 12/13 at 11:59pm (no late days).</td>\n</tr>\n<tr class="warning" id="opt">\n<td colspan="4">\n<b>Supplementary Notes</b>\n<ol>\n<li>Online Learning and the Perceptron Algorithm [<a href="http://cs229.stanford.edu/notes2019fall/cs229-notes6.pdf">pdf</a>] </li>\n<li>Binary classification with +/-1 labels [<a href="http://cs229.stanford.edu/extra-notes/loss-functions.pdf">pdf</a>]</li>\n<!-- <li>Functional after implementing stump_booster.m in PS2. [<a href="http://cs229.stanford.edu/extra-notes/boosting_example.m">here</a>] </li> -->\n<li>The representer theorem [<a href="http://cs229.stanford.edu/extra-notes/representer-function.pdf">pdf</a>]</li>\n<li>Hoeffding\'s inequality [<a href="http://cs229.stanford.edu/extra-notes/hoeffding.pdf">pdf</a>] </li>\n</ol></td>\n</tr>\n<!--\n  <tr class="alert">\n    <td colspan="4">\n    <b>Friday Lecture Notes</b>\n    <ol>\n      <li>Convex Optimization Overview, Part I [<a href="http://cs229.stanford.edu/section/cs229-cvxopt.ps">ps</a>] [<a href="http://cs229.stanford.edu/section/cs229-cvxopt.pdf">pdf</a>]</li>\n      <li>Convex Optimization Overview, Part II [<a href="http://cs229.stanford.edu/section/cs229-cvxopt2.ps">ps</a>] [<a href="http://cs229.stanford.edu/section/cs229-cvxopt2.pdf">pdf</a>] </li>\n      <li>Hidden Markov Models [<a href="http://cs229.stanford.edu/section/cs229-hmm.ps">ps</a>] [<a href="http://cs229.stanford.edu/section/cs229-hmm.pdf">pdf</a>] </li>\n      <li>Gaussian Processes [<a href="http://cs229.stanford.edu/section/cs229-gaussian_processes.pdf">pdf</a>] </li>\n    </ol></td>\n  </tr>\n  -->\n<tr>\n<td colspan="4">\n<b>Other Resources</b>\n<ol>\n<li>Advice on applying machine learning: Slides from Andrew\'s lecture on getting machine learning algorithms to work in practice can be found <a href="http://cs229.stanford.edu/materials/ML-advice.pdf">here</a>.<br/></li>\n<li>Previous projects: A list of last year\'s final projects can be found <a href="http://cs229.stanford.edu/proj2017/index.html">here</a>.<br/></li>\n<!--<li>Matlab resources: Here are a couple of Matlab tutorials that you might find helpful: <a href="http://www.math.ucsd.edu/~bdriver/21d-s99/matlab-primer.html">http://www.math.ucsd.edu/~bdriver/21d-s99/matlab-primer.html</a> and <a href="http://www.math.mtu.edu/~msgocken/intro/node1.html">http://www.math.mtu.edu/~msgocken/intro/node1.html</a>. For emacs users only: If you plan to run Matlab in emacs, here are <a href="http://cs229.stanford.edu/materials/matlab.el">matlab.el</a>, and a helpful <a href="http://cs229.stanford.edu/materials/emacs">.emac\'s</a> file.<br></li>\n        <li>Octave resources: For a free alternative to Matlab, check out <a href="http://www.gnu.org/software/octave/">GNU Octave</a>. The official documentation is available <a href="http://www.gnu.org/software/octave/doc/interpreter/">here</a>. Some useful tutorials on Octave include <a href="http://en.wikibooks.org/wiki/Octave_Programming_Tutorial">http://en.wikibooks.org/wiki/Octave_Programming_Tutorial</a> and <a href="http://www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf">http://www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf</a> .<br></li>-->\n<li>Data: Here is the <a href="http://www.ics.uci.edu/~mlearn/MLRepository.html">UCI Machine learning repository</a>, which contains a large collection of standard datasets for testing learning algorithms. If you want to see examples of recent work in machine learning, start by taking a look at the conferences <a href="http://www.nips.cc/">NIPS</a>(all old NIPS papers are online) and ICML. Some other related conferences include UAI, AAAI, IJCAI.<br/></li>\n<li>Viewing PostScript and PDF files: Depending on the computer you are using, you may be able to download a <a href="http://www.cs.wisc.edu/~ghost/">PostScript</a> viewer or <a href="http://www.adobe.com/products/acrobat/readstep2_allversions.html">PDF viewer</a> for it if you don\'t already have one.<br/></li>\n<li><a href="https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning">Machine learning study guides tailored to CS 229</a> by Afshine Amidi and Shervine Amidi.</li>\n</ol>\n</td>\n</tr>\n</tbody></table>\n</div>\n<script crossorigin="anonymous" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>\n<script crossorigin="anonymous" integrity="sha384-b/U6ypiBEHpOf/4+1nzFpr53nxSS+GLCkfwBdFNTxtclqqenISfwAzpKaMNFNmj4" src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.11.0/umd/popper.min.js"></script>\n<script crossorigin="anonymous" integrity="sha384-h0AbiXch4ZDo7tp9hKZ4TsHbi047NrKGLO3SEJAg45jXxnGIfYzk4Si90RDIqNm1" src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/js/bootstrap.min.js"></script>\n</body></html>\n'